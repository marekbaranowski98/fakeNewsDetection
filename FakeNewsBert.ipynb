{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7sQwp_1Ps1_",
    "tags": []
   },
   "source": [
    "# Model rozpoznający fake news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSmRwSH0Ps2J",
    "tags": []
   },
   "source": [
    "# Wstępne ustawienia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F39zVi2aP3PL",
    "outputId": "4b125ae7-454c-409f-de46-8cd1333af9f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummaryX in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: matplotlib in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (3.7.0)\n",
      "Requirement already satisfied: tqdm in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (4.64.1)\n",
      "Requirement already satisfied: wordcloud in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (1.8.2.2)\n",
      "Requirement already satisfied: ipywidgets in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (8.0.4)\n",
      "Requirement already satisfied: widgetsnbextension in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (4.0.5)\n",
      "Requirement already satisfied: scikit-learn in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: seaborn in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: transformers in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (4.26.1)\n",
      "Requirement already satisfied: numpy in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from torchsummaryX) (1.23.5)\n",
      "Requirement already satisfied: pandas in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from torchsummaryX) (1.5.3)\n",
      "Requirement already satisfied: torch in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from torchsummaryX) (1.13.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipywidgets) (8.10.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipywidgets) (6.21.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipywidgets) (3.0.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: requests in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: psutil in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.4)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (8.0.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.6)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: nest-asyncio in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.2.0)\n",
      "Requirement already satisfied: pyzmq>=20 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.0.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: backcall in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.37)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: decorator in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: stack-data in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pickleshare in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from pandas->torchsummaryX) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummaryX matplotlib tqdm wordcloud ipywidgets widgetsnbextension scikit-learn seaborn transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa2JcSuuPs2J"
   },
   "source": [
    "## Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ddxePKaHPs2K"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import string\n",
    "import requests\n",
    "import transformers\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from torchsummaryX import summary\n",
    "from torch.utils import tensorboard\n",
    "from random import randrange\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLB_1_wKPs2K"
   },
   "source": [
    "## Zdefiniowanie stałych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "V6lprunbPs2L"
   },
   "outputs": [],
   "source": [
    "NIGHTLY = False\n",
    "USE_MPS = False\n",
    "\n",
    "LOGS_PATH = 'logi/FakeNews'\n",
    "DATA_PATH = 'data/FakeNews'\n",
    "GRAPH_PATH = 'graph/FakeNews'\n",
    "PROJECTOR_PATH = 'projector/FakeNews'\n",
    "MODEL_PATH = 'model/FakeNews'\n",
    "DATA_FILENAME = 'WelFake.csv'\n",
    "\n",
    "DATA_URL = 'https://zenodo.org/record/4561253/files/WELFake_Dataset.csv?download=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RFhEFTBRPs2L"
   },
   "outputs": [],
   "source": [
    "TRAIN_LEN_SPLIT = 0.7\n",
    "VAL_LEN_SPLIT = 0.1\n",
    "TEST_LEN_SPLIT = 0.2\n",
    "\n",
    "tmpSum = (TRAIN_LEN_SPLIT + VAL_LEN_SPLIT + TEST_LEN_SPLIT)\n",
    "assert(tmpSum <= 1.0)\n",
    "assert(tmpSum > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ustawienie rozszerzeń notebooka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001B[32mOK\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqdKaLrlPs2L"
   },
   "source": [
    "## Wybór urządzenia do treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_nM3UaZ_Ps2M"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available() and USE_MPS:\n",
    "  DEVICE = torch.device('mps')\n",
    "else:\n",
    "  DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3knHrx0Ps2M"
   },
   "source": [
    "## Utworzenie potrzebnych katalogów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3apTAyUyPs2M"
   },
   "outputs": [],
   "source": [
    "list_folders = [\n",
    "  LOGS_PATH,\n",
    "  DATA_PATH,\n",
    "  PROJECTOR_PATH,\n",
    "  MODEL_PATH\n",
    "]\n",
    "\n",
    "for x in list_folders:\n",
    "  if not os.path.exists(x):\n",
    "    os.makedirs(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a9pAg90Ps2M",
    "tags": []
   },
   "source": [
    "# Zbiór danych\n",
    "Pobrane z\n",
    "https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz-M1BY3Ps2M",
    "tags": []
   },
   "source": [
    "## Funkcja pobierająca CSV from URL_PATH save to DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TU590y32Ps2N"
   },
   "outputs": [],
   "source": [
    "def download_csv(url: string, file_path: string, filename: string):\n",
    "  req = requests.get(url)\n",
    "  body = req.content\n",
    "\n",
    "  with open(os.path.join(file_path, filename), 'wb') as f:\n",
    "    f.write(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0dcLevAPs2N",
    "tags": []
   },
   "source": [
    "## Pobranie pliku CSV i zapisanie go do pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qayA8p7TPs2N"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(DATA_PATH, DATA_FILENAME)):\n",
    "  download_csv(DATA_URL, DATA_PATH, DATA_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvh6cQtZPs2O",
    "tags": []
   },
   "source": [
    "## Wczytanie pobranego pliku do pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZiyC92DUPs2O"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(os.path.join(DATA_PATH, DATA_FILENAME)))\n",
    "# data = pd.read_csv(DATA_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkVSABCqPs2O",
    "tags": []
   },
   "source": [
    "### Zmiana nazwy pól"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "u6nRCR0rPs2O",
    "outputId": "1a2db997-2675-4c47-bfde-cd7bd5f587a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              title  \\\n",
       "0   0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1   1                                                NaN   \n",
       "2   2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3   3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4   4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label category  \n",
       "0  No comment is expected from Barack Obama Membe...      1     fake  \n",
       "1     Did they post their votes for Hillary already?      1     fake  \n",
       "2   Now, most of the demonstrators gathered last ...      1     fake  \n",
       "3  A dozen politically active pastors came here f...      0     real  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1     fake  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.rename(columns={'Unnamed: 0': 'ID'})\n",
    "data['category'] = np.where(data['label'] == 1, 'fake', 'real')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFK9Kgi3Ps2P",
    "tags": []
   },
   "source": [
    "### Usunięcie wierszy bez artykułu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aMvYb_PtPs2P"
   },
   "outputs": [],
   "source": [
    "data = data.replace(r'^\\s*$', np.nan, regex=True)\n",
    "data = data.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podsumowanie liczby artykułów z podziałem na kategorie\n",
    "\n",
    "1 - Fake<br>0 - Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fO0NK85QPs2S",
    "tags": []
   },
   "source": [
    "## Podział zbioru danych\n",
    "\n",
    "\n",
    "Zbiór danych zostanie podzielony na 3 zbiory:\n",
    "- treningowe — dane do uczenia\n",
    "- walidacyjne — do oceny modelu podczas treningu\n",
    "- testowe - do oceny modelu po treningu\n",
    "\n",
    "Dane zostaną podzielone zgodnie ze zdefiniowanym stosunkiem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Loo0FMWaPs2S"
   },
   "outputs": [],
   "source": [
    "data_train = data[:int(len(data)*TRAIN_LEN_SPLIT)]\n",
    "\n",
    "data_val = data[\n",
    "  int(len(data)*TRAIN_LEN_SPLIT):int(len(data)*TRAIN_LEN_SPLIT + len(data)*VAL_LEN_SPLIT)\n",
    "]\n",
    "\n",
    "data_test = data[\n",
    "  int(len(data)*TRAIN_LEN_SPLIT + len(data)*VAL_LEN_SPLIT)\n",
    "  :\n",
    "  int(len(data)*TRAIN_LEN_SPLIT + len(data)*VAL_LEN_SPLIT + len(data)*TEST_LEN_SPLIT)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3Ded6yjPs2S",
    "tags": []
   },
   "source": [
    "### Sprawdzenie rozmiaru poszczególnych zbiorów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVngTRuMPs2S",
    "tags": []
   },
   "source": [
    "#### Zbiór treningowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ou_qE4M_Ps2S",
    "outputId": "ecfa85cb-3a97-423a-f41c-3da91c43d621"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49945, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98K-75H2Ps2S"
   },
   "source": [
    "#### Zbiór walidacyjny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjvejKSTPs2S",
    "outputId": "f432ff7c-b298-4833-ddb9-bb8bab5ebb79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7135, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RF0N96ewPs2S"
   },
   "source": [
    "#### Zbiór testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVuMXBVdPs2S",
    "outputId": "a2bbdd08-8b66-4314-fc36-8c3ac6b26ae9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14271, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02RuSNVIPs2T",
    "tags": []
   },
   "source": [
    "# Trening modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zdefiniowanie ustawień"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TRANSFER_VERSION = 'bert'\n",
    "MODEL_TRANSFER_PATH = os.path.join(os.path.join(MODEL_PATH, f'model_{MODEL_TRANSFER_VERSION}.pt'))\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "\n",
    "SEQ_LENGTH = 400\n",
    "\n",
    "PATIENCE = 10\n",
    "DELTA = 0\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "CLIP_GRAD = 15\n",
    "DROPOUT = 0.4\n",
    "\n",
    "TOKENIZER = transformers.BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHyPzHXWPs2T",
    "tags": []
   },
   "source": [
    "## Utworzenie klas pomocniczych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Klasa EarlyStoping\n",
    "\n",
    "Klasa pozwalająca zatrzymać trenowanie modelu, jeżeli model nie będzie uczył się dla zbioru walidacyjne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoping:\n",
    "  def __init__(self, patience, delta = 0, operator = np.less, model_path = None):\n",
    "    self.PATIENCE = patience\n",
    "    self.DELTA = delta\n",
    "    self.operator = operator\n",
    "    self.model_path = model_path\n",
    "\n",
    "    self.trigger = 0\n",
    "    self.best_score = None\n",
    "        \n",
    "  def continue_training(self, actual_value, model_save):\n",
    "    if self.best_score is not None and self.operator(self.best_score + self.DELTA, actual_value):\n",
    "      self.trigger += 1\n",
    "            \n",
    "      if self.trigger >= self.PATIENCE:\n",
    "        return False\n",
    "    else:\n",
    "      self.trigger = 0\n",
    "      self.best_score = actual_value\n",
    "      if self.model_path is not None and model is not None:\n",
    "        torch.save(model_save.state_dict(), self.model_path)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TInvM4jEPs2T",
    "tags": []
   },
   "source": [
    "### Funkcja tworząca logger TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vKiZxa_3Ps2T"
   },
   "outputs": [],
   "source": [
    "def get_tensorboard_writer():\n",
    "  path = os.path.join(LOGS_PATH, f'{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}_v{MODEL_TRANSFER_VERSION}')\n",
    "  writer_tmp = tensorboard.SummaryWriter(path)\n",
    "  \n",
    "  for filename in os.listdir(path):\n",
    "    file_path = os.path.join(path, filename)\n",
    "    if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "      os.unlink(file_path)\n",
    "    \n",
    "  return writer_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie klasy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FakeNewsDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, text, fake, tokenizer, max_len):\n",
    "    self.text = text\n",
    "    self.fake = fake\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.text)\n",
    "  \n",
    "  def __getitem__(self, i):\n",
    "    text = str(self.text[i])\n",
    "    fake = self.fake[i]\n",
    "    \n",
    "    enc = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      truncation=True,\n",
    "      return_token_type_ids=False,\n",
    "      padding='max_length',\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "      'text': text,\n",
    "      'input_ids': enc['input_ids'].flatten(),\n",
    "      'attention_mask': enc['attention_mask'].flatten(),\n",
    "      'fake': torch.tensor(fake, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYJh25zuPs2T",
    "tags": []
   },
   "source": [
    "## Przygotowanie danych do treningu modelu w PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9tjwfnjPs2T",
    "tags": []
   },
   "source": [
    "### Utworzenie tensorów dla wczytanych zbiorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "44qxDivTPs2T"
   },
   "outputs": [],
   "source": [
    "train_data = FakeNewsDataset(\n",
    "  data_train.text.to_numpy(),\n",
    "  data_train.label.to_numpy(),\n",
    "  TOKENIZER,\n",
    "  max_len=SEQ_LENGTH\n",
    ")\n",
    "\n",
    "val_data = FakeNewsDataset(\n",
    "  data_val.text.to_numpy(),\n",
    "  data_val.label.to_numpy(),\n",
    "  TOKENIZER,\n",
    "  max_len=SEQ_LENGTH\n",
    ")\n",
    "\n",
    "test_data = FakeNewsDataset(\n",
    "  data_test.text.to_numpy(),\n",
    "  data_test.label.to_numpy(),\n",
    "  TOKENIZER,\n",
    "  max_len=SEQ_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Hrz6XDJPs2T",
    "tags": []
   },
   "source": [
    "### Stworzenie DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COAElSxePs2T",
    "outputId": "aa9fa367-4ec0-47ba-9eff-ab5972f7aaed"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True, num_workers=4\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  val_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True, num_workers=4\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  test_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sikXNTJCPs2T",
    "tags": []
   },
   "source": [
    "## Definicja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "LsAU3f8ZPs2U"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "  def __init__(self, output_size, drop=0):\n",
    "    super(Net, self).__init__()\n",
    "    self.output_size = output_size\n",
    "    \n",
    "    self.bert = transformers.BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop = torch.nn.Dropout(drop)\n",
    "    self.fc = torch.nn.Linear(self.bert.config.hidden_size, self.output_size)\n",
    "    self.sf = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, x, m):\n",
    "    out = self.bert(input_ids=x, attention_mask=m)[1]\n",
    "    out = self.drop(out)\n",
    "    out = self.fc(out)\n",
    "    out = self.sf(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4LYWkfMPs2U",
    "tags": []
   },
   "source": [
    "## Utworzenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "iV52diVdPs2U"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = Net(2, DROPOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_Va1V4WPs2U",
    "tags": []
   },
   "source": [
    "### Przeniesienie modelu na urządzenie do treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfXEUsQwPs2U",
    "outputId": "4903389c-2b3b-40a1-a178-67a805b38b8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.4, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (sf): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnsjXBbrPs2U",
    "tags": []
   },
   "source": [
    "### Wyświetlenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "zATcXouePs2U",
    "outputId": "9b99605a-03de-42fe-8709-5688ee71f8c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/po/anaconda3/envs/marekBaranowski/lib/python3.10/site-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: The default value of numeric_only in DataFrame.sum is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_sum = df.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================================\n",
      "                                                    Kernel Shape  \\\n",
      "Layer                                                              \n",
      "0_bert.embeddings.Embedding_word_embeddings         [768, 28996]   \n",
      "1_bert.embeddings.Embedding_token_type_embeddings       [768, 2]   \n",
      "2_bert.embeddings.Embedding_position_embeddings       [768, 512]   \n",
      "3_bert.embeddings.LayerNorm_LayerNorm                      [768]   \n",
      "4_bert.embeddings.Dropout_dropout                              -   \n",
      "5_bert.encoder.layer.0.attention.self.Linear_query    [768, 768]   \n",
      "6_bert.encoder.layer.0.attention.self.Linear_key      [768, 768]   \n",
      "7_bert.encoder.layer.0.attention.self.Linear_value    [768, 768]   \n",
      "8_bert.encoder.layer.0.attention.self.Dropout_d...             -   \n",
      "9_bert.encoder.layer.0.attention.output.Linear_...    [768, 768]   \n",
      "10_bert.encoder.layer.0.attention.output.Dropou...             -   \n",
      "11_bert.encoder.layer.0.attention.output.LayerN...         [768]   \n",
      "12_bert.encoder.layer.0.intermediate.Linear_dense    [768, 3072]   \n",
      "13_bert.encoder.layer.0.intermediate.GELUActiva...             -   \n",
      "14_bert.encoder.layer.0.output.Linear_dense          [3072, 768]   \n",
      "15_bert.encoder.layer.0.output.Dropout_dropout                 -   \n",
      "16_bert.encoder.layer.0.output.LayerNorm_LayerNorm         [768]   \n",
      "17_bert.encoder.layer.1.attention.self.Linear_q...    [768, 768]   \n",
      "18_bert.encoder.layer.1.attention.self.Linear_key     [768, 768]   \n",
      "19_bert.encoder.layer.1.attention.self.Linear_v...    [768, 768]   \n",
      "20_bert.encoder.layer.1.attention.self.Dropout_...             -   \n",
      "21_bert.encoder.layer.1.attention.output.Linear...    [768, 768]   \n",
      "22_bert.encoder.layer.1.attention.output.Dropou...             -   \n",
      "23_bert.encoder.layer.1.attention.output.LayerN...         [768]   \n",
      "24_bert.encoder.layer.1.intermediate.Linear_dense    [768, 3072]   \n",
      "25_bert.encoder.layer.1.intermediate.GELUActiva...             -   \n",
      "26_bert.encoder.layer.1.output.Linear_dense          [3072, 768]   \n",
      "27_bert.encoder.layer.1.output.Dropout_dropout                 -   \n",
      "28_bert.encoder.layer.1.output.LayerNorm_LayerNorm         [768]   \n",
      "29_bert.encoder.layer.2.attention.self.Linear_q...    [768, 768]   \n",
      "30_bert.encoder.layer.2.attention.self.Linear_key     [768, 768]   \n",
      "31_bert.encoder.layer.2.attention.self.Linear_v...    [768, 768]   \n",
      "32_bert.encoder.layer.2.attention.self.Dropout_...             -   \n",
      "33_bert.encoder.layer.2.attention.output.Linear...    [768, 768]   \n",
      "34_bert.encoder.layer.2.attention.output.Dropou...             -   \n",
      "35_bert.encoder.layer.2.attention.output.LayerN...         [768]   \n",
      "36_bert.encoder.layer.2.intermediate.Linear_dense    [768, 3072]   \n",
      "37_bert.encoder.layer.2.intermediate.GELUActiva...             -   \n",
      "38_bert.encoder.layer.2.output.Linear_dense          [3072, 768]   \n",
      "39_bert.encoder.layer.2.output.Dropout_dropout                 -   \n",
      "40_bert.encoder.layer.2.output.LayerNorm_LayerNorm         [768]   \n",
      "41_bert.encoder.layer.3.attention.self.Linear_q...    [768, 768]   \n",
      "42_bert.encoder.layer.3.attention.self.Linear_key     [768, 768]   \n",
      "43_bert.encoder.layer.3.attention.self.Linear_v...    [768, 768]   \n",
      "44_bert.encoder.layer.3.attention.self.Dropout_...             -   \n",
      "45_bert.encoder.layer.3.attention.output.Linear...    [768, 768]   \n",
      "46_bert.encoder.layer.3.attention.output.Dropou...             -   \n",
      "47_bert.encoder.layer.3.attention.output.LayerN...         [768]   \n",
      "48_bert.encoder.layer.3.intermediate.Linear_dense    [768, 3072]   \n",
      "49_bert.encoder.layer.3.intermediate.GELUActiva...             -   \n",
      "50_bert.encoder.layer.3.output.Linear_dense          [3072, 768]   \n",
      "51_bert.encoder.layer.3.output.Dropout_dropout                 -   \n",
      "52_bert.encoder.layer.3.output.LayerNorm_LayerNorm         [768]   \n",
      "53_bert.encoder.layer.4.attention.self.Linear_q...    [768, 768]   \n",
      "54_bert.encoder.layer.4.attention.self.Linear_key     [768, 768]   \n",
      "55_bert.encoder.layer.4.attention.self.Linear_v...    [768, 768]   \n",
      "56_bert.encoder.layer.4.attention.self.Dropout_...             -   \n",
      "57_bert.encoder.layer.4.attention.output.Linear...    [768, 768]   \n",
      "58_bert.encoder.layer.4.attention.output.Dropou...             -   \n",
      "59_bert.encoder.layer.4.attention.output.LayerN...         [768]   \n",
      "60_bert.encoder.layer.4.intermediate.Linear_dense    [768, 3072]   \n",
      "61_bert.encoder.layer.4.intermediate.GELUActiva...             -   \n",
      "62_bert.encoder.layer.4.output.Linear_dense          [3072, 768]   \n",
      "63_bert.encoder.layer.4.output.Dropout_dropout                 -   \n",
      "64_bert.encoder.layer.4.output.LayerNorm_LayerNorm         [768]   \n",
      "65_bert.encoder.layer.5.attention.self.Linear_q...    [768, 768]   \n",
      "66_bert.encoder.layer.5.attention.self.Linear_key     [768, 768]   \n",
      "67_bert.encoder.layer.5.attention.self.Linear_v...    [768, 768]   \n",
      "68_bert.encoder.layer.5.attention.self.Dropout_...             -   \n",
      "69_bert.encoder.layer.5.attention.output.Linear...    [768, 768]   \n",
      "70_bert.encoder.layer.5.attention.output.Dropou...             -   \n",
      "71_bert.encoder.layer.5.attention.output.LayerN...         [768]   \n",
      "72_bert.encoder.layer.5.intermediate.Linear_dense    [768, 3072]   \n",
      "73_bert.encoder.layer.5.intermediate.GELUActiva...             -   \n",
      "74_bert.encoder.layer.5.output.Linear_dense          [3072, 768]   \n",
      "75_bert.encoder.layer.5.output.Dropout_dropout                 -   \n",
      "76_bert.encoder.layer.5.output.LayerNorm_LayerNorm         [768]   \n",
      "77_bert.encoder.layer.6.attention.self.Linear_q...    [768, 768]   \n",
      "78_bert.encoder.layer.6.attention.self.Linear_key     [768, 768]   \n",
      "79_bert.encoder.layer.6.attention.self.Linear_v...    [768, 768]   \n",
      "80_bert.encoder.layer.6.attention.self.Dropout_...             -   \n",
      "81_bert.encoder.layer.6.attention.output.Linear...    [768, 768]   \n",
      "82_bert.encoder.layer.6.attention.output.Dropou...             -   \n",
      "83_bert.encoder.layer.6.attention.output.LayerN...         [768]   \n",
      "84_bert.encoder.layer.6.intermediate.Linear_dense    [768, 3072]   \n",
      "85_bert.encoder.layer.6.intermediate.GELUActiva...             -   \n",
      "86_bert.encoder.layer.6.output.Linear_dense          [3072, 768]   \n",
      "87_bert.encoder.layer.6.output.Dropout_dropout                 -   \n",
      "88_bert.encoder.layer.6.output.LayerNorm_LayerNorm         [768]   \n",
      "89_bert.encoder.layer.7.attention.self.Linear_q...    [768, 768]   \n",
      "90_bert.encoder.layer.7.attention.self.Linear_key     [768, 768]   \n",
      "91_bert.encoder.layer.7.attention.self.Linear_v...    [768, 768]   \n",
      "92_bert.encoder.layer.7.attention.self.Dropout_...             -   \n",
      "93_bert.encoder.layer.7.attention.output.Linear...    [768, 768]   \n",
      "94_bert.encoder.layer.7.attention.output.Dropou...             -   \n",
      "95_bert.encoder.layer.7.attention.output.LayerN...         [768]   \n",
      "96_bert.encoder.layer.7.intermediate.Linear_dense    [768, 3072]   \n",
      "97_bert.encoder.layer.7.intermediate.GELUActiva...             -   \n",
      "98_bert.encoder.layer.7.output.Linear_dense          [3072, 768]   \n",
      "99_bert.encoder.layer.7.output.Dropout_dropout                 -   \n",
      "100_bert.encoder.layer.7.output.LayerNorm_Layer...         [768]   \n",
      "101_bert.encoder.layer.8.attention.self.Linear_...    [768, 768]   \n",
      "102_bert.encoder.layer.8.attention.self.Linear_key    [768, 768]   \n",
      "103_bert.encoder.layer.8.attention.self.Linear_...    [768, 768]   \n",
      "104_bert.encoder.layer.8.attention.self.Dropout...             -   \n",
      "105_bert.encoder.layer.8.attention.output.Linea...    [768, 768]   \n",
      "106_bert.encoder.layer.8.attention.output.Dropo...             -   \n",
      "107_bert.encoder.layer.8.attention.output.Layer...         [768]   \n",
      "108_bert.encoder.layer.8.intermediate.Linear_dense   [768, 3072]   \n",
      "109_bert.encoder.layer.8.intermediate.GELUActiv...             -   \n",
      "110_bert.encoder.layer.8.output.Linear_dense         [3072, 768]   \n",
      "111_bert.encoder.layer.8.output.Dropout_dropout                -   \n",
      "112_bert.encoder.layer.8.output.LayerNorm_Layer...         [768]   \n",
      "113_bert.encoder.layer.9.attention.self.Linear_...    [768, 768]   \n",
      "114_bert.encoder.layer.9.attention.self.Linear_key    [768, 768]   \n",
      "115_bert.encoder.layer.9.attention.self.Linear_...    [768, 768]   \n",
      "116_bert.encoder.layer.9.attention.self.Dropout...             -   \n",
      "117_bert.encoder.layer.9.attention.output.Linea...    [768, 768]   \n",
      "118_bert.encoder.layer.9.attention.output.Dropo...             -   \n",
      "119_bert.encoder.layer.9.attention.output.Layer...         [768]   \n",
      "120_bert.encoder.layer.9.intermediate.Linear_dense   [768, 3072]   \n",
      "121_bert.encoder.layer.9.intermediate.GELUActiv...             -   \n",
      "122_bert.encoder.layer.9.output.Linear_dense         [3072, 768]   \n",
      "123_bert.encoder.layer.9.output.Dropout_dropout                -   \n",
      "124_bert.encoder.layer.9.output.LayerNorm_Layer...         [768]   \n",
      "125_bert.encoder.layer.10.attention.self.Linear...    [768, 768]   \n",
      "126_bert.encoder.layer.10.attention.self.Linear...    [768, 768]   \n",
      "127_bert.encoder.layer.10.attention.self.Linear...    [768, 768]   \n",
      "128_bert.encoder.layer.10.attention.self.Dropou...             -   \n",
      "129_bert.encoder.layer.10.attention.output.Line...    [768, 768]   \n",
      "130_bert.encoder.layer.10.attention.output.Drop...             -   \n",
      "131_bert.encoder.layer.10.attention.output.Laye...         [768]   \n",
      "132_bert.encoder.layer.10.intermediate.Linear_d...   [768, 3072]   \n",
      "133_bert.encoder.layer.10.intermediate.GELUActi...             -   \n",
      "134_bert.encoder.layer.10.output.Linear_dense        [3072, 768]   \n",
      "135_bert.encoder.layer.10.output.Dropout_dropout               -   \n",
      "136_bert.encoder.layer.10.output.LayerNorm_Laye...         [768]   \n",
      "137_bert.encoder.layer.11.attention.self.Linear...    [768, 768]   \n",
      "138_bert.encoder.layer.11.attention.self.Linear...    [768, 768]   \n",
      "139_bert.encoder.layer.11.attention.self.Linear...    [768, 768]   \n",
      "140_bert.encoder.layer.11.attention.self.Dropou...             -   \n",
      "141_bert.encoder.layer.11.attention.output.Line...    [768, 768]   \n",
      "142_bert.encoder.layer.11.attention.output.Drop...             -   \n",
      "143_bert.encoder.layer.11.attention.output.Laye...         [768]   \n",
      "144_bert.encoder.layer.11.intermediate.Linear_d...   [768, 3072]   \n",
      "145_bert.encoder.layer.11.intermediate.GELUActi...             -   \n",
      "146_bert.encoder.layer.11.output.Linear_dense        [3072, 768]   \n",
      "147_bert.encoder.layer.11.output.Dropout_dropout               -   \n",
      "148_bert.encoder.layer.11.output.LayerNorm_Laye...         [768]   \n",
      "149_bert.pooler.Linear_dense                          [768, 768]   \n",
      "150_bert.pooler.Tanh_activation                                -   \n",
      "151_drop                                                       -   \n",
      "152_fc                                                  [768, 2]   \n",
      "153_sf                                                         -   \n",
      "\n",
      "                                                          Output Shape  \\\n",
      "Layer                                                                    \n",
      "0_bert.embeddings.Embedding_word_embeddings             [16, 400, 768]   \n",
      "1_bert.embeddings.Embedding_token_type_embeddings       [16, 400, 768]   \n",
      "2_bert.embeddings.Embedding_position_embeddings          [1, 400, 768]   \n",
      "3_bert.embeddings.LayerNorm_LayerNorm                   [16, 400, 768]   \n",
      "4_bert.embeddings.Dropout_dropout                       [16, 400, 768]   \n",
      "5_bert.encoder.layer.0.attention.self.Linear_query      [16, 400, 768]   \n",
      "6_bert.encoder.layer.0.attention.self.Linear_key        [16, 400, 768]   \n",
      "7_bert.encoder.layer.0.attention.self.Linear_value      [16, 400, 768]   \n",
      "8_bert.encoder.layer.0.attention.self.Dropout_d...  [16, 12, 400, 400]   \n",
      "9_bert.encoder.layer.0.attention.output.Linear_...      [16, 400, 768]   \n",
      "10_bert.encoder.layer.0.attention.output.Dropou...      [16, 400, 768]   \n",
      "11_bert.encoder.layer.0.attention.output.LayerN...      [16, 400, 768]   \n",
      "12_bert.encoder.layer.0.intermediate.Linear_dense      [16, 400, 3072]   \n",
      "13_bert.encoder.layer.0.intermediate.GELUActiva...     [16, 400, 3072]   \n",
      "14_bert.encoder.layer.0.output.Linear_dense             [16, 400, 768]   \n",
      "15_bert.encoder.layer.0.output.Dropout_dropout          [16, 400, 768]   \n",
      "16_bert.encoder.layer.0.output.LayerNorm_LayerNorm      [16, 400, 768]   \n",
      "17_bert.encoder.layer.1.attention.self.Linear_q...      [16, 400, 768]   \n",
      "18_bert.encoder.layer.1.attention.self.Linear_key       [16, 400, 768]   \n",
      "19_bert.encoder.layer.1.attention.self.Linear_v...      [16, 400, 768]   \n",
      "20_bert.encoder.layer.1.attention.self.Dropout_...  [16, 12, 400, 400]   \n",
      "21_bert.encoder.layer.1.attention.output.Linear...      [16, 400, 768]   \n",
      "22_bert.encoder.layer.1.attention.output.Dropou...      [16, 400, 768]   \n",
      "23_bert.encoder.layer.1.attention.output.LayerN...      [16, 400, 768]   \n",
      "24_bert.encoder.layer.1.intermediate.Linear_dense      [16, 400, 3072]   \n",
      "25_bert.encoder.layer.1.intermediate.GELUActiva...     [16, 400, 3072]   \n",
      "26_bert.encoder.layer.1.output.Linear_dense             [16, 400, 768]   \n",
      "27_bert.encoder.layer.1.output.Dropout_dropout          [16, 400, 768]   \n",
      "28_bert.encoder.layer.1.output.LayerNorm_LayerNorm      [16, 400, 768]   \n",
      "29_bert.encoder.layer.2.attention.self.Linear_q...      [16, 400, 768]   \n",
      "30_bert.encoder.layer.2.attention.self.Linear_key       [16, 400, 768]   \n",
      "31_bert.encoder.layer.2.attention.self.Linear_v...      [16, 400, 768]   \n",
      "32_bert.encoder.layer.2.attention.self.Dropout_...  [16, 12, 400, 400]   \n",
      "33_bert.encoder.layer.2.attention.output.Linear...      [16, 400, 768]   \n",
      "34_bert.encoder.layer.2.attention.output.Dropou...      [16, 400, 768]   \n",
      "35_bert.encoder.layer.2.attention.output.LayerN...      [16, 400, 768]   \n",
      "36_bert.encoder.layer.2.intermediate.Linear_dense      [16, 400, 3072]   \n",
      "37_bert.encoder.layer.2.intermediate.GELUActiva...     [16, 400, 3072]   \n",
      "38_bert.encoder.layer.2.output.Linear_dense             [16, 400, 768]   \n",
      "39_bert.encoder.layer.2.output.Dropout_dropout          [16, 400, 768]   \n",
      "40_bert.encoder.layer.2.output.LayerNorm_LayerNorm      [16, 400, 768]   \n",
      "41_bert.encoder.layer.3.attention.self.Linear_q...      [16, 400, 768]   \n",
      "42_bert.encoder.layer.3.attention.self.Linear_key       [16, 400, 768]   \n",
      "43_bert.encoder.layer.3.attention.self.Linear_v...      [16, 400, 768]   \n",
      "44_bert.encoder.layer.3.attention.self.Dropout_...  [16, 12, 400, 400]   \n",
      "45_bert.encoder.layer.3.attention.output.Linear...      [16, 400, 768]   \n",
      "46_bert.encoder.layer.3.attention.output.Dropou...      [16, 400, 768]   \n",
      "47_bert.encoder.layer.3.attention.output.LayerN...      [16, 400, 768]   \n",
      "48_bert.encoder.layer.3.intermediate.Linear_dense      [16, 400, 3072]   \n",
      "49_bert.encoder.layer.3.intermediate.GELUActiva...     [16, 400, 3072]   \n",
      "50_bert.encoder.layer.3.output.Linear_dense             [16, 400, 768]   \n",
      "51_bert.encoder.layer.3.output.Dropout_dropout          [16, 400, 768]   \n",
      "52_bert.encoder.layer.3.output.LayerNorm_LayerNorm      [16, 400, 768]   \n",
      "53_bert.encoder.layer.4.attention.self.Linear_q...      [16, 400, 768]   \n",
      "54_bert.encoder.layer.4.attention.self.Linear_key       [16, 400, 768]   \n",
      "55_bert.encoder.layer.4.attention.self.Linear_v...      [16, 400, 768]   \n",
      "56_bert.encoder.layer.4.attention.self.Dropout_...  [16, 12, 400, 400]   \n",
      "57_bert.encoder.layer.4.attention.output.Linear...      [16, 400, 768]   \n",
      "58_bert.encoder.layer.4.attention.output.Dropou...      [16, 400, 768]   \n",
      "59_bert.encoder.layer.4.attention.output.LayerN...      [16, 400, 768]   \n",
      "60_bert.encoder.layer.4.intermediate.Linear_dense      [16, 400, 3072]   \n",
      "61_bert.encoder.layer.4.intermediate.GELUActiva...     [16, 400, 3072]   \n",
      "62_bert.encoder.layer.4.output.Linear_dense             [16, 400, 768]   \n",
      "63_bert.encoder.layer.4.output.Dropout_dropout          [16, 400, 768]   \n",
      "64_bert.encoder.layer.4.output.LayerNorm_LayerNorm      [16, 400, 768]   \n",
      "65_bert.encoder.layer.5.attention.self.Linear_q...      [16, 400, 768]   \n",
      "66_bert.encoder.layer.5.attention.self.Linear_key       [16, 400, 768]   \n",
      "67_bert.encoder.layer.5.attention.self.Linear_v...      [16, 400, 768]   \n",
      "68_bert.encoder.layer.5.attention.self.Dropout_...  [16, 12, 400, 400]   \n",
      "69_bert.encoder.layer.5.attention.output.Linear...      [16, 400, 768]   \n",
      "70_bert.encoder.layer.5.attention.output.Dropou...      [16, 400, 768]   \n",
      "71_bert.encoder.layer.5.attention.output.LayerN...      [16, 400, 768]   \n",
      "72_bert.encoder.layer.5.intermediate.Linear_dense      [16, 400, 3072]   \n",
      "73_bert.encoder.layer.5.intermediate.GELUActiva...     [16, 400, 3072]   \n",
      "74_bert.encoder.layer.5.output.Linear_dense             [16, 400, 768]   \n",
      "75_bert.encoder.layer.5.output.Dropout_dropout          [16, 400, 768]   \n",
      "76_bert.encoder.layer.5.output.LayerNorm_LayerNorm      [16, 400, 768]   \n",
      "77_bert.encoder.layer.6.attention.self.Linear_q...      [16, 400, 768]   \n",
      "78_bert.encoder.layer.6.attention.self.Linear_key       [16, 400, 768]   \n",
      "79_bert.encoder.layer.6.attention.self.Linear_v...      [16, 400, 768]   \n",
      "80_bert.encoder.layer.6.attention.self.Dropout_...  [16, 12, 400, 400]   \n",
      "81_bert.encoder.layer.6.attention.output.Linear...      [16, 400, 768]   \n",
      "82_bert.encoder.layer.6.attention.output.Dropou...      [16, 400, 768]   \n",
      "83_bert.encoder.layer.6.attention.output.LayerN...      [16, 400, 768]   \n",
      "84_bert.encoder.layer.6.intermediate.Linear_dense      [16, 400, 3072]   \n",
      "85_bert.encoder.layer.6.intermediate.GELUActiva...     [16, 400, 3072]   \n",
      "86_bert.encoder.layer.6.output.Linear_dense             [16, 400, 768]   \n",
      "87_bert.encoder.layer.6.output.Dropout_dropout          [16, 400, 768]   \n",
      "88_bert.encoder.layer.6.output.LayerNorm_LayerNorm      [16, 400, 768]   \n",
      "89_bert.encoder.layer.7.attention.self.Linear_q...      [16, 400, 768]   \n",
      "90_bert.encoder.layer.7.attention.self.Linear_key       [16, 400, 768]   \n",
      "91_bert.encoder.layer.7.attention.self.Linear_v...      [16, 400, 768]   \n",
      "92_bert.encoder.layer.7.attention.self.Dropout_...  [16, 12, 400, 400]   \n",
      "93_bert.encoder.layer.7.attention.output.Linear...      [16, 400, 768]   \n",
      "94_bert.encoder.layer.7.attention.output.Dropou...      [16, 400, 768]   \n",
      "95_bert.encoder.layer.7.attention.output.LayerN...      [16, 400, 768]   \n",
      "96_bert.encoder.layer.7.intermediate.Linear_dense      [16, 400, 3072]   \n",
      "97_bert.encoder.layer.7.intermediate.GELUActiva...     [16, 400, 3072]   \n",
      "98_bert.encoder.layer.7.output.Linear_dense             [16, 400, 768]   \n",
      "99_bert.encoder.layer.7.output.Dropout_dropout          [16, 400, 768]   \n",
      "100_bert.encoder.layer.7.output.LayerNorm_Layer...      [16, 400, 768]   \n",
      "101_bert.encoder.layer.8.attention.self.Linear_...      [16, 400, 768]   \n",
      "102_bert.encoder.layer.8.attention.self.Linear_key      [16, 400, 768]   \n",
      "103_bert.encoder.layer.8.attention.self.Linear_...      [16, 400, 768]   \n",
      "104_bert.encoder.layer.8.attention.self.Dropout...  [16, 12, 400, 400]   \n",
      "105_bert.encoder.layer.8.attention.output.Linea...      [16, 400, 768]   \n",
      "106_bert.encoder.layer.8.attention.output.Dropo...      [16, 400, 768]   \n",
      "107_bert.encoder.layer.8.attention.output.Layer...      [16, 400, 768]   \n",
      "108_bert.encoder.layer.8.intermediate.Linear_dense     [16, 400, 3072]   \n",
      "109_bert.encoder.layer.8.intermediate.GELUActiv...     [16, 400, 3072]   \n",
      "110_bert.encoder.layer.8.output.Linear_dense            [16, 400, 768]   \n",
      "111_bert.encoder.layer.8.output.Dropout_dropout         [16, 400, 768]   \n",
      "112_bert.encoder.layer.8.output.LayerNorm_Layer...      [16, 400, 768]   \n",
      "113_bert.encoder.layer.9.attention.self.Linear_...      [16, 400, 768]   \n",
      "114_bert.encoder.layer.9.attention.self.Linear_key      [16, 400, 768]   \n",
      "115_bert.encoder.layer.9.attention.self.Linear_...      [16, 400, 768]   \n",
      "116_bert.encoder.layer.9.attention.self.Dropout...  [16, 12, 400, 400]   \n",
      "117_bert.encoder.layer.9.attention.output.Linea...      [16, 400, 768]   \n",
      "118_bert.encoder.layer.9.attention.output.Dropo...      [16, 400, 768]   \n",
      "119_bert.encoder.layer.9.attention.output.Layer...      [16, 400, 768]   \n",
      "120_bert.encoder.layer.9.intermediate.Linear_dense     [16, 400, 3072]   \n",
      "121_bert.encoder.layer.9.intermediate.GELUActiv...     [16, 400, 3072]   \n",
      "122_bert.encoder.layer.9.output.Linear_dense            [16, 400, 768]   \n",
      "123_bert.encoder.layer.9.output.Dropout_dropout         [16, 400, 768]   \n",
      "124_bert.encoder.layer.9.output.LayerNorm_Layer...      [16, 400, 768]   \n",
      "125_bert.encoder.layer.10.attention.self.Linear...      [16, 400, 768]   \n",
      "126_bert.encoder.layer.10.attention.self.Linear...      [16, 400, 768]   \n",
      "127_bert.encoder.layer.10.attention.self.Linear...      [16, 400, 768]   \n",
      "128_bert.encoder.layer.10.attention.self.Dropou...  [16, 12, 400, 400]   \n",
      "129_bert.encoder.layer.10.attention.output.Line...      [16, 400, 768]   \n",
      "130_bert.encoder.layer.10.attention.output.Drop...      [16, 400, 768]   \n",
      "131_bert.encoder.layer.10.attention.output.Laye...      [16, 400, 768]   \n",
      "132_bert.encoder.layer.10.intermediate.Linear_d...     [16, 400, 3072]   \n",
      "133_bert.encoder.layer.10.intermediate.GELUActi...     [16, 400, 3072]   \n",
      "134_bert.encoder.layer.10.output.Linear_dense           [16, 400, 768]   \n",
      "135_bert.encoder.layer.10.output.Dropout_dropout        [16, 400, 768]   \n",
      "136_bert.encoder.layer.10.output.LayerNorm_Laye...      [16, 400, 768]   \n",
      "137_bert.encoder.layer.11.attention.self.Linear...      [16, 400, 768]   \n",
      "138_bert.encoder.layer.11.attention.self.Linear...      [16, 400, 768]   \n",
      "139_bert.encoder.layer.11.attention.self.Linear...      [16, 400, 768]   \n",
      "140_bert.encoder.layer.11.attention.self.Dropou...  [16, 12, 400, 400]   \n",
      "141_bert.encoder.layer.11.attention.output.Line...      [16, 400, 768]   \n",
      "142_bert.encoder.layer.11.attention.output.Drop...      [16, 400, 768]   \n",
      "143_bert.encoder.layer.11.attention.output.Laye...      [16, 400, 768]   \n",
      "144_bert.encoder.layer.11.intermediate.Linear_d...     [16, 400, 3072]   \n",
      "145_bert.encoder.layer.11.intermediate.GELUActi...     [16, 400, 3072]   \n",
      "146_bert.encoder.layer.11.output.Linear_dense           [16, 400, 768]   \n",
      "147_bert.encoder.layer.11.output.Dropout_dropout        [16, 400, 768]   \n",
      "148_bert.encoder.layer.11.output.LayerNorm_Laye...      [16, 400, 768]   \n",
      "149_bert.pooler.Linear_dense                                 [16, 768]   \n",
      "150_bert.pooler.Tanh_activation                              [16, 768]   \n",
      "151_drop                                                     [16, 768]   \n",
      "152_fc                                                         [16, 2]   \n",
      "153_sf                                                         [16, 2]   \n",
      "\n",
      "                                                        Params   Mult-Adds  \n",
      "Layer                                                                       \n",
      "0_bert.embeddings.Embedding_word_embeddings         22.268928M  22.268928M  \n",
      "1_bert.embeddings.Embedding_token_type_embeddings       1.536k      1.536k  \n",
      "2_bert.embeddings.Embedding_position_embeddings       393.216k    393.216k  \n",
      "3_bert.embeddings.LayerNorm_LayerNorm                   1.536k       768.0  \n",
      "4_bert.embeddings.Dropout_dropout                            -           -  \n",
      "5_bert.encoder.layer.0.attention.self.Linear_query    590.592k    589.824k  \n",
      "6_bert.encoder.layer.0.attention.self.Linear_key      590.592k    589.824k  \n",
      "7_bert.encoder.layer.0.attention.self.Linear_value    590.592k    589.824k  \n",
      "8_bert.encoder.layer.0.attention.self.Dropout_d...           -           -  \n",
      "9_bert.encoder.layer.0.attention.output.Linear_...    590.592k    589.824k  \n",
      "10_bert.encoder.layer.0.attention.output.Dropou...           -           -  \n",
      "11_bert.encoder.layer.0.attention.output.LayerN...      1.536k       768.0  \n",
      "12_bert.encoder.layer.0.intermediate.Linear_dense    2.362368M   2.359296M  \n",
      "13_bert.encoder.layer.0.intermediate.GELUActiva...           -           -  \n",
      "14_bert.encoder.layer.0.output.Linear_dense          2.360064M   2.359296M  \n",
      "15_bert.encoder.layer.0.output.Dropout_dropout               -           -  \n",
      "16_bert.encoder.layer.0.output.LayerNorm_LayerNorm      1.536k       768.0  \n",
      "17_bert.encoder.layer.1.attention.self.Linear_q...    590.592k    589.824k  \n",
      "18_bert.encoder.layer.1.attention.self.Linear_key     590.592k    589.824k  \n",
      "19_bert.encoder.layer.1.attention.self.Linear_v...    590.592k    589.824k  \n",
      "20_bert.encoder.layer.1.attention.self.Dropout_...           -           -  \n",
      "21_bert.encoder.layer.1.attention.output.Linear...    590.592k    589.824k  \n",
      "22_bert.encoder.layer.1.attention.output.Dropou...           -           -  \n",
      "23_bert.encoder.layer.1.attention.output.LayerN...      1.536k       768.0  \n",
      "24_bert.encoder.layer.1.intermediate.Linear_dense    2.362368M   2.359296M  \n",
      "25_bert.encoder.layer.1.intermediate.GELUActiva...           -           -  \n",
      "26_bert.encoder.layer.1.output.Linear_dense          2.360064M   2.359296M  \n",
      "27_bert.encoder.layer.1.output.Dropout_dropout               -           -  \n",
      "28_bert.encoder.layer.1.output.LayerNorm_LayerNorm      1.536k       768.0  \n",
      "29_bert.encoder.layer.2.attention.self.Linear_q...    590.592k    589.824k  \n",
      "30_bert.encoder.layer.2.attention.self.Linear_key     590.592k    589.824k  \n",
      "31_bert.encoder.layer.2.attention.self.Linear_v...    590.592k    589.824k  \n",
      "32_bert.encoder.layer.2.attention.self.Dropout_...           -           -  \n",
      "33_bert.encoder.layer.2.attention.output.Linear...    590.592k    589.824k  \n",
      "34_bert.encoder.layer.2.attention.output.Dropou...           -           -  \n",
      "35_bert.encoder.layer.2.attention.output.LayerN...      1.536k       768.0  \n",
      "36_bert.encoder.layer.2.intermediate.Linear_dense    2.362368M   2.359296M  \n",
      "37_bert.encoder.layer.2.intermediate.GELUActiva...           -           -  \n",
      "38_bert.encoder.layer.2.output.Linear_dense          2.360064M   2.359296M  \n",
      "39_bert.encoder.layer.2.output.Dropout_dropout               -           -  \n",
      "40_bert.encoder.layer.2.output.LayerNorm_LayerNorm      1.536k       768.0  \n",
      "41_bert.encoder.layer.3.attention.self.Linear_q...    590.592k    589.824k  \n",
      "42_bert.encoder.layer.3.attention.self.Linear_key     590.592k    589.824k  \n",
      "43_bert.encoder.layer.3.attention.self.Linear_v...    590.592k    589.824k  \n",
      "44_bert.encoder.layer.3.attention.self.Dropout_...           -           -  \n",
      "45_bert.encoder.layer.3.attention.output.Linear...    590.592k    589.824k  \n",
      "46_bert.encoder.layer.3.attention.output.Dropou...           -           -  \n",
      "47_bert.encoder.layer.3.attention.output.LayerN...      1.536k       768.0  \n",
      "48_bert.encoder.layer.3.intermediate.Linear_dense    2.362368M   2.359296M  \n",
      "49_bert.encoder.layer.3.intermediate.GELUActiva...           -           -  \n",
      "50_bert.encoder.layer.3.output.Linear_dense          2.360064M   2.359296M  \n",
      "51_bert.encoder.layer.3.output.Dropout_dropout               -           -  \n",
      "52_bert.encoder.layer.3.output.LayerNorm_LayerNorm      1.536k       768.0  \n",
      "53_bert.encoder.layer.4.attention.self.Linear_q...    590.592k    589.824k  \n",
      "54_bert.encoder.layer.4.attention.self.Linear_key     590.592k    589.824k  \n",
      "55_bert.encoder.layer.4.attention.self.Linear_v...    590.592k    589.824k  \n",
      "56_bert.encoder.layer.4.attention.self.Dropout_...           -           -  \n",
      "57_bert.encoder.layer.4.attention.output.Linear...    590.592k    589.824k  \n",
      "58_bert.encoder.layer.4.attention.output.Dropou...           -           -  \n",
      "59_bert.encoder.layer.4.attention.output.LayerN...      1.536k       768.0  \n",
      "60_bert.encoder.layer.4.intermediate.Linear_dense    2.362368M   2.359296M  \n",
      "61_bert.encoder.layer.4.intermediate.GELUActiva...           -           -  \n",
      "62_bert.encoder.layer.4.output.Linear_dense          2.360064M   2.359296M  \n",
      "63_bert.encoder.layer.4.output.Dropout_dropout               -           -  \n",
      "64_bert.encoder.layer.4.output.LayerNorm_LayerNorm      1.536k       768.0  \n",
      "65_bert.encoder.layer.5.attention.self.Linear_q...    590.592k    589.824k  \n",
      "66_bert.encoder.layer.5.attention.self.Linear_key     590.592k    589.824k  \n",
      "67_bert.encoder.layer.5.attention.self.Linear_v...    590.592k    589.824k  \n",
      "68_bert.encoder.layer.5.attention.self.Dropout_...           -           -  \n",
      "69_bert.encoder.layer.5.attention.output.Linear...    590.592k    589.824k  \n",
      "70_bert.encoder.layer.5.attention.output.Dropou...           -           -  \n",
      "71_bert.encoder.layer.5.attention.output.LayerN...      1.536k       768.0  \n",
      "72_bert.encoder.layer.5.intermediate.Linear_dense    2.362368M   2.359296M  \n",
      "73_bert.encoder.layer.5.intermediate.GELUActiva...           -           -  \n",
      "74_bert.encoder.layer.5.output.Linear_dense          2.360064M   2.359296M  \n",
      "75_bert.encoder.layer.5.output.Dropout_dropout               -           -  \n",
      "76_bert.encoder.layer.5.output.LayerNorm_LayerNorm      1.536k       768.0  \n",
      "77_bert.encoder.layer.6.attention.self.Linear_q...    590.592k    589.824k  \n",
      "78_bert.encoder.layer.6.attention.self.Linear_key     590.592k    589.824k  \n",
      "79_bert.encoder.layer.6.attention.self.Linear_v...    590.592k    589.824k  \n",
      "80_bert.encoder.layer.6.attention.self.Dropout_...           -           -  \n",
      "81_bert.encoder.layer.6.attention.output.Linear...    590.592k    589.824k  \n",
      "82_bert.encoder.layer.6.attention.output.Dropou...           -           -  \n",
      "83_bert.encoder.layer.6.attention.output.LayerN...      1.536k       768.0  \n",
      "84_bert.encoder.layer.6.intermediate.Linear_dense    2.362368M   2.359296M  \n",
      "85_bert.encoder.layer.6.intermediate.GELUActiva...           -           -  \n",
      "86_bert.encoder.layer.6.output.Linear_dense          2.360064M   2.359296M  \n",
      "87_bert.encoder.layer.6.output.Dropout_dropout               -           -  \n",
      "88_bert.encoder.layer.6.output.LayerNorm_LayerNorm      1.536k       768.0  \n",
      "89_bert.encoder.layer.7.attention.self.Linear_q...    590.592k    589.824k  \n",
      "90_bert.encoder.layer.7.attention.self.Linear_key     590.592k    589.824k  \n",
      "91_bert.encoder.layer.7.attention.self.Linear_v...    590.592k    589.824k  \n",
      "92_bert.encoder.layer.7.attention.self.Dropout_...           -           -  \n",
      "93_bert.encoder.layer.7.attention.output.Linear...    590.592k    589.824k  \n",
      "94_bert.encoder.layer.7.attention.output.Dropou...           -           -  \n",
      "95_bert.encoder.layer.7.attention.output.LayerN...      1.536k       768.0  \n",
      "96_bert.encoder.layer.7.intermediate.Linear_dense    2.362368M   2.359296M  \n",
      "97_bert.encoder.layer.7.intermediate.GELUActiva...           -           -  \n",
      "98_bert.encoder.layer.7.output.Linear_dense          2.360064M   2.359296M  \n",
      "99_bert.encoder.layer.7.output.Dropout_dropout               -           -  \n",
      "100_bert.encoder.layer.7.output.LayerNorm_Layer...      1.536k       768.0  \n",
      "101_bert.encoder.layer.8.attention.self.Linear_...    590.592k    589.824k  \n",
      "102_bert.encoder.layer.8.attention.self.Linear_key    590.592k    589.824k  \n",
      "103_bert.encoder.layer.8.attention.self.Linear_...    590.592k    589.824k  \n",
      "104_bert.encoder.layer.8.attention.self.Dropout...           -           -  \n",
      "105_bert.encoder.layer.8.attention.output.Linea...    590.592k    589.824k  \n",
      "106_bert.encoder.layer.8.attention.output.Dropo...           -           -  \n",
      "107_bert.encoder.layer.8.attention.output.Layer...      1.536k       768.0  \n",
      "108_bert.encoder.layer.8.intermediate.Linear_dense   2.362368M   2.359296M  \n",
      "109_bert.encoder.layer.8.intermediate.GELUActiv...           -           -  \n",
      "110_bert.encoder.layer.8.output.Linear_dense         2.360064M   2.359296M  \n",
      "111_bert.encoder.layer.8.output.Dropout_dropout              -           -  \n",
      "112_bert.encoder.layer.8.output.LayerNorm_Layer...      1.536k       768.0  \n",
      "113_bert.encoder.layer.9.attention.self.Linear_...    590.592k    589.824k  \n",
      "114_bert.encoder.layer.9.attention.self.Linear_key    590.592k    589.824k  \n",
      "115_bert.encoder.layer.9.attention.self.Linear_...    590.592k    589.824k  \n",
      "116_bert.encoder.layer.9.attention.self.Dropout...           -           -  \n",
      "117_bert.encoder.layer.9.attention.output.Linea...    590.592k    589.824k  \n",
      "118_bert.encoder.layer.9.attention.output.Dropo...           -           -  \n",
      "119_bert.encoder.layer.9.attention.output.Layer...      1.536k       768.0  \n",
      "120_bert.encoder.layer.9.intermediate.Linear_dense   2.362368M   2.359296M  \n",
      "121_bert.encoder.layer.9.intermediate.GELUActiv...           -           -  \n",
      "122_bert.encoder.layer.9.output.Linear_dense         2.360064M   2.359296M  \n",
      "123_bert.encoder.layer.9.output.Dropout_dropout              -           -  \n",
      "124_bert.encoder.layer.9.output.LayerNorm_Layer...      1.536k       768.0  \n",
      "125_bert.encoder.layer.10.attention.self.Linear...    590.592k    589.824k  \n",
      "126_bert.encoder.layer.10.attention.self.Linear...    590.592k    589.824k  \n",
      "127_bert.encoder.layer.10.attention.self.Linear...    590.592k    589.824k  \n",
      "128_bert.encoder.layer.10.attention.self.Dropou...           -           -  \n",
      "129_bert.encoder.layer.10.attention.output.Line...    590.592k    589.824k  \n",
      "130_bert.encoder.layer.10.attention.output.Drop...           -           -  \n",
      "131_bert.encoder.layer.10.attention.output.Laye...      1.536k       768.0  \n",
      "132_bert.encoder.layer.10.intermediate.Linear_d...   2.362368M   2.359296M  \n",
      "133_bert.encoder.layer.10.intermediate.GELUActi...           -           -  \n",
      "134_bert.encoder.layer.10.output.Linear_dense        2.360064M   2.359296M  \n",
      "135_bert.encoder.layer.10.output.Dropout_dropout             -           -  \n",
      "136_bert.encoder.layer.10.output.LayerNorm_Laye...      1.536k       768.0  \n",
      "137_bert.encoder.layer.11.attention.self.Linear...    590.592k    589.824k  \n",
      "138_bert.encoder.layer.11.attention.self.Linear...    590.592k    589.824k  \n",
      "139_bert.encoder.layer.11.attention.self.Linear...    590.592k    589.824k  \n",
      "140_bert.encoder.layer.11.attention.self.Dropou...           -           -  \n",
      "141_bert.encoder.layer.11.attention.output.Line...    590.592k    589.824k  \n",
      "142_bert.encoder.layer.11.attention.output.Drop...           -           -  \n",
      "143_bert.encoder.layer.11.attention.output.Laye...      1.536k       768.0  \n",
      "144_bert.encoder.layer.11.intermediate.Linear_d...   2.362368M   2.359296M  \n",
      "145_bert.encoder.layer.11.intermediate.GELUActi...           -           -  \n",
      "146_bert.encoder.layer.11.output.Linear_dense        2.360064M   2.359296M  \n",
      "147_bert.encoder.layer.11.output.Dropout_dropout             -           -  \n",
      "148_bert.encoder.layer.11.output.LayerNorm_Laye...      1.536k       768.0  \n",
      "149_bert.pooler.Linear_dense                          590.592k    589.824k  \n",
      "150_bert.pooler.Tanh_activation                              -           -  \n",
      "151_drop                                                     -           -  \n",
      "152_fc                                                  1.538k      1.536k  \n",
      "153_sf                                                       -           -  \n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "                           Totals\n",
      "Total params           108.31181M\n",
      "Trainable params       108.31181M\n",
      "Non-trainable params          0.0\n",
      "Mult-Adds             108.208896M\n",
      "===================================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_bert.embeddings.Embedding_word_embeddings</th>\n",
       "      <td>[768, 28996]</td>\n",
       "      <td>[16, 400, 768]</td>\n",
       "      <td>22268928.0</td>\n",
       "      <td>22268928.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_bert.embeddings.Embedding_token_type_embeddings</th>\n",
       "      <td>[768, 2]</td>\n",
       "      <td>[16, 400, 768]</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>1536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_bert.embeddings.Embedding_position_embeddings</th>\n",
       "      <td>[768, 512]</td>\n",
       "      <td>[1, 400, 768]</td>\n",
       "      <td>393216.0</td>\n",
       "      <td>393216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_bert.embeddings.LayerNorm_LayerNorm</th>\n",
       "      <td>[768]</td>\n",
       "      <td>[16, 400, 768]</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_bert.embeddings.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[16, 400, 768]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149_bert.pooler.Linear_dense</th>\n",
       "      <td>[768, 768]</td>\n",
       "      <td>[16, 768]</td>\n",
       "      <td>590592.0</td>\n",
       "      <td>589824.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150_bert.pooler.Tanh_activation</th>\n",
       "      <td>-</td>\n",
       "      <td>[16, 768]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151_drop</th>\n",
       "      <td>-</td>\n",
       "      <td>[16, 768]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152_fc</th>\n",
       "      <td>[768, 2]</td>\n",
       "      <td>[16, 2]</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>1536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153_sf</th>\n",
       "      <td>-</td>\n",
       "      <td>[16, 2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Kernel Shape  \\\n",
       "Layer                                                             \n",
       "0_bert.embeddings.Embedding_word_embeddings        [768, 28996]   \n",
       "1_bert.embeddings.Embedding_token_type_embeddings      [768, 2]   \n",
       "2_bert.embeddings.Embedding_position_embeddings      [768, 512]   \n",
       "3_bert.embeddings.LayerNorm_LayerNorm                     [768]   \n",
       "4_bert.embeddings.Dropout_dropout                             -   \n",
       "...                                                         ...   \n",
       "149_bert.pooler.Linear_dense                         [768, 768]   \n",
       "150_bert.pooler.Tanh_activation                               -   \n",
       "151_drop                                                      -   \n",
       "152_fc                                                 [768, 2]   \n",
       "153_sf                                                        -   \n",
       "\n",
       "                                                     Output Shape      Params  \\\n",
       "Layer                                                                           \n",
       "0_bert.embeddings.Embedding_word_embeddings        [16, 400, 768]  22268928.0   \n",
       "1_bert.embeddings.Embedding_token_type_embeddings  [16, 400, 768]      1536.0   \n",
       "2_bert.embeddings.Embedding_position_embeddings     [1, 400, 768]    393216.0   \n",
       "3_bert.embeddings.LayerNorm_LayerNorm              [16, 400, 768]      1536.0   \n",
       "4_bert.embeddings.Dropout_dropout                  [16, 400, 768]         NaN   \n",
       "...                                                           ...         ...   \n",
       "149_bert.pooler.Linear_dense                            [16, 768]    590592.0   \n",
       "150_bert.pooler.Tanh_activation                         [16, 768]         NaN   \n",
       "151_drop                                                [16, 768]         NaN   \n",
       "152_fc                                                    [16, 2]      1538.0   \n",
       "153_sf                                                    [16, 2]         NaN   \n",
       "\n",
       "                                                    Mult-Adds  \n",
       "Layer                                                          \n",
       "0_bert.embeddings.Embedding_word_embeddings        22268928.0  \n",
       "1_bert.embeddings.Embedding_token_type_embeddings      1536.0  \n",
       "2_bert.embeddings.Embedding_position_embeddings      393216.0  \n",
       "3_bert.embeddings.LayerNorm_LayerNorm                   768.0  \n",
       "4_bert.embeddings.Dropout_dropout                         NaN  \n",
       "...                                                       ...  \n",
       "149_bert.pooler.Linear_dense                         589824.0  \n",
       "150_bert.pooler.Tanh_activation                           NaN  \n",
       "151_drop                                                  NaN  \n",
       "152_fc                                                 1536.0  \n",
       "153_sf                                                    NaN  \n",
       "\n",
       "[154 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(train_loader))\n",
    "\n",
    "summary(\n",
    "  model, \n",
    "  x['input_ids'].to(DEVICE),\n",
    "  x['attention_mask'].to(DEVICE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX4t8g2BPs2U",
    "tags": []
   },
   "source": [
    "### Wczytanie wytrenowanego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "IpAz_ps9Ps2U"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(MODEL_TRANSFER_PATH):\n",
    "  model.load_state_dict(torch.load(MODEL_TRANSFER_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTcXiDUcPs2U",
    "tags": []
   },
   "source": [
    "### Kompilacja modelu\n",
    "\n",
    "W najnowszych wersjach treningu kompilacja przyśpiesza trening modelu, ale jest dostępna tylko na CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "bW1YdUVBPs2V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na kompilacje modelu potrzebne było None\n"
     ]
    }
   ],
   "source": [
    "czas_kompilacji = None\n",
    "if DEVICE.type == 'cuda' and NIGHTLY:\n",
    "  start_kompilacji = datetime.now()\n",
    "  model = torch.compile(model, mode='reduce-overhead')\n",
    "  czas_kompilacji = datetime.now() - start_kompilacji\n",
    "  \n",
    "print(f'Na kompilacje modelu potrzebne było {czas_kompilacji}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZ7UA2VOPs2V",
    "tags": []
   },
   "source": [
    "## Przebieg treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "eeAdSYoOPs2V",
    "outputId": "0bc6b4bb-517e-48d8-a32c-303170ebdb69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|█| 3121/3121 [23:13<00:00,  2.24 batch/s, loss=0.061, acc=0.97\n",
      "Epoch 2/100: 100%|█| 3121/3121 [23:18<00:00,  2.23 batch/s, loss=0.015, acc=0.99\n",
      "Epoch 3/100: 100%|█| 3121/3121 [23:31<00:00,  2.21 batch/s, loss=0.007, acc=0.99\n",
      "Epoch 4/100: 100%|█| 3121/3121 [23:31<00:00,  2.21 batch/s, loss=0.005, acc=0.99\n",
      "Epoch 5/100: 100%|█| 3121/3121 [23:34<00:00,  2.21 batch/s, loss=0.004, acc=0.99\n",
      "Epoch 6/100: 100%|█| 3121/3121 [23:33<00:00,  2.21 batch/s, loss=0.004, acc=0.99\n",
      "Epoch 7/100: 100%|█| 3121/3121 [23:29<00:00,  2.21 batch/s, loss=0.002, acc=0.99\n",
      "Epoch 8/100: 100%|█| 3121/3121 [23:19<00:00,  2.23 batch/s, loss=0.002, acc=0.99\n",
      "Epoch 9/100: 100%|█| 3121/3121 [23:41<00:00,  2.20 batch/s, loss=0.002, acc=0.99\n",
      "Epoch 10/100: 100%|██| 3121/3121 [23:18<00:00,  2.23 batch/s, loss=0.002, acc=1]\n",
      "Epoch 11/100: 100%|█| 3121/3121 [23:28<00:00,  2.22 batch/s, loss=0.002, acc=0.9\n",
      "Epoch 12/100: 100%|██| 3121/3121 [23:26<00:00,  2.22 batch/s, loss=0.002, acc=1]\n",
      "Epoch 13/100: 100%|██| 3121/3121 [23:28<00:00,  2.22 batch/s, loss=0.001, acc=1]\n",
      "Epoch 14/100: 100%|██| 3121/3121 [23:27<00:00,  2.22 batch/s, loss=0.001, acc=1]\n",
      "Epoch 15/100: 100%|██| 3121/3121 [23:24<00:00,  2.22 batch/s, loss=0.001, acc=1]\n",
      "Epoch 16/100: 100%|██| 3121/3121 [23:35<00:00,  2.20 batch/s, loss=0.001, acc=1]\n",
      "Epoch 17/100: 100%|██| 3121/3121 [23:31<00:00,  2.21 batch/s, loss=0.001, acc=1]\n",
      "Epoch 18/100: 100%|██| 3121/3121 [23:29<00:00,  2.21 batch/s, loss=0.001, acc=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stoping Epoch: 18 Train loss 0.00078 Train accuracy 0.99954 Val loss: 0.04457 Val accuracy: 0.99201\n",
      "Model wytrenował sie w 7:20:57.676163\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)\n",
    "criterion = torch.nn.functional.nll_loss\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=len(train_loader) * EPOCHS\n",
    ")\n",
    "     \n",
    "early_stopping = EarlyStoping(PATIENCE, delta=DELTA, operator=np.greater_equal, model_path=MODEL_TRANSFER_PATH)\n",
    "\n",
    "writer = get_tensorboard_writer()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "start_treningu = datetime.now()\n",
    "for epoch in range(EPOCHS):\n",
    "  with tqdm(train_loader, unit=' batch') as tepoch:\n",
    "    tepoch.set_description(f'Epoch {epoch+1}/{EPOCHS}')\n",
    "\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    losses = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, d in enumerate(tepoch):\n",
    "      input_ids = d['input_ids'].to(DEVICE)\n",
    "      attention_mask = d['attention_mask'].to(DEVICE)\n",
    "      target = d['fake'].to(DEVICE)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "                  \n",
    "      output = model(input_ids, attention_mask)\n",
    "      loss = criterion(output, target)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_GRAD)\n",
    "      optimizer.step()\n",
    "      \n",
    "      losses.append(loss.item())\n",
    "      predictions = torch.argmax(output, dim=1)\n",
    "      correct += predictions.eq(target.view_as(predictions)).sum().detach()\n",
    "      scheduler.step()\n",
    "      \n",
    "      # scheduler.step(np.mean(losses))\n",
    "\n",
    "      tepoch.set_postfix({\n",
    "        'loss': round(np.mean(losses), 3),\n",
    "        'acc': round((correct / ((batch_idx + 1) * BATCH_SIZE)).item(), 3)\n",
    "      })\n",
    "\n",
    "    train_loss = np.mean(losses)\n",
    "    acc = (correct / float(len(train_loader.dataset))).item()\n",
    "  \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(acc)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    val_loss = []\n",
    "        \n",
    "    with torch.no_grad():\n",
    "      for d in val_loader:\n",
    "        input_ids = d['input_ids'].to(DEVICE)\n",
    "        attention_mask = d['attention_mask'].to(DEVICE)\n",
    "        target = d['fake'].to(DEVICE)\n",
    "  \n",
    "        output = model(input_ids, attention_mask)\n",
    "\n",
    "        val_loss.append(criterion(output, target).item())\n",
    "\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        correct += predictions.eq(target.view_as(predictions)).sum().detach()\n",
    "    val_acc = (correct / float(len(val_loader.dataset)))\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    val_losses.append(np.mean(val_loss))\n",
    "\n",
    "    # scheduler.step(val_acc)\n",
    "    \n",
    "    writer.add_scalars('accuracy', {\n",
    "      'train': acc,\n",
    "      'validation': val_acc\n",
    "    }, epoch)\n",
    "        \n",
    "    writer.add_scalars('loss', {\n",
    "      'train': train_loss,\n",
    "      'validation': np.mean(val_loss)\n",
    "    }, epoch)\n",
    "    \n",
    "    if not early_stopping.continue_training(val_acc.item(), model):\n",
    "      tepoch.write(\n",
    "        f'Early stoping Epoch: {epoch+1} \\\n",
    "Train loss {train_loss:.5f} Train accuracy {acc:.5f} \\\n",
    "Val loss: {np.mean(val_loss):.5f} Val accuracy: {val_acc:.5f}'\n",
    "      )\n",
    "      break\n",
    "\n",
    "#   tepoch.write(\n",
    "#     f'Train loss {train_loss:.5f} Train accuracy {acc:.5f} \\\n",
    "# Val loss: {np.mean(val_loss):.5f} Val accuracy: {val_acc:.5f}'\n",
    "#   )\n",
    "writer.close()\n",
    "print(f'Model wytrenował sie w {datetime.now() - start_treningu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcja testująca model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(model, criterion, loader):\n",
    "  correct = 0\n",
    "  test_loss = []\n",
    "  \n",
    "  y_predictions = []\n",
    "  y_test = []\n",
    "\n",
    "  model.eval()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for batch_idx, d in enumerate(tqdm(loader)):\n",
    "      input_ids = d['input_ids'].to(DEVICE)\n",
    "      attention_mask = d['attention_mask'].to(DEVICE)\n",
    "      target = d['fake'].to(DEVICE)\n",
    "  \n",
    "      output = model(input_ids, attention_mask)\n",
    "\n",
    "      test_loss.append(criterion(output, target).item())\n",
    "\n",
    "      predictions = torch.argmax(output, dim=1)\n",
    "      correct += predictions.eq(target.view_as(predictions)).sum().detach()\n",
    "\n",
    "      y_predictions.extend(predictions)\n",
    "      y_test.extend(target)\n",
    "      \n",
    "    test_acc = (correct / float(len(test_loader.dataset)))\n",
    "  return test_loss, test_acc, torch.stack(y_predictions).cpu(), torch.stack(y_test).cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprawdzenie ostatniej wersji modelu na zestawie testowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 891/891 [02:04<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 0.03125 Test acc: 99.41139%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracies, _, _ = test_model(model, torch.nn.functional.nll_loss, test_loader)\n",
    "print(f'Test loss {np.mean(test_loss):.5f} Test acc: {(test_accuracies * 100):.5f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wczytanie najlepszej wersji modelu\n",
    "\n",
    "Zostanie załadowana wersja modelu, która uzyskała najniższa wartość funkcji straty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_TRANSFER_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprawdzenie modelu na zestawie testowym\n",
    "\n",
    "Zostanie sprawdzany zupełnie nowy zestaw danych. Model nigdy wcześniej nie widział danych z tego zestawu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8oFljKGqOSpM",
    "outputId": "8a379619-42b5-4529-fab9-d9e28cfeda1a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 891/891 [01:51<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 0.02143 Test acc: 99.46745%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracies, y_predictions, y_test = test_model(model, torch.nn.functional.nll_loss, test_loader)\n",
    "\n",
    "print(f'Test loss {np.mean(test_loss):.5f} Test acc: {(test_accuracies * 100):.5f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wyświetlenie macierzy pomyłek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf = confusion_matrix(y_predictions, y_test)\n",
    "df_cm = pd.DataFrame(\n",
    "  cf,\n",
    "  index=[i for i in ['Przewidywany Real', 'Przewidywany FakeNews']],\n",
    "  columns=[i for i in ['Faktyczny Real', 'Faktyczny FakeNews']]\n",
    ")\n",
    "\n",
    "sns.heatmap(df_cm, annot=True, cmap='RdYlGn_r', fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapisanie grafu utworzonego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = next(iter(train_loader))\n",
    "\n",
    "writer_model = tensorboard.SummaryWriter(GRAPH_PATH)\n",
    "writer_model.add_graph(\n",
    "  model,\n",
    "  (x['input_ids'].to(DEVICE), x['attention_mask'].to(DEVICE))\n",
    ")\n",
    "\n",
    "writer_model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sprawdzenie modelu na 1 próbce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wybranie próbki do sprawdzenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_probe = randrange(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wyświetlenie wybranego artykułu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6848      I don t hate these people. They are just ang...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.ID == random_probe].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sprawdzenie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Przesłanie wybranego tekstu do modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = TOKENIZER.encode_plus(\n",
    "  data[data.ID == random_probe].text.to_numpy()[0],\n",
    "  #data.text.[random_probe],\n",
    "  add_special_tokens=True,\n",
    "  max_length=SEQ_LENGTH,\n",
    "  truncation=True,\n",
    "  return_token_type_ids=False,\n",
    "  padding='max_length',\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt'\n",
    ")\n",
    "\n",
    "output = model(\n",
    "  t['input_ids'].to(DEVICE),\n",
    "  t['attention_mask'].to(DEVICE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Porównanie odpowiedzi modelu z wartością oczekiwana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Według modelu ten artykuł jest prawdziwy i jest tego pewny na 100.00%.\n"
     ]
    }
   ],
   "source": [
    "ans_model = torch.exp(output)\n",
    "print(\n",
    "  f'Według modelu ten artykuł jest {\"prawdziwy\" if torch.argmax(ans_model) == 0 else \"fałszywy\"} \\\n",
    "i jest tego pewny na {ans_model[0][torch.argmax(ans_model)]*100:.2f}%.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prawidłowa odpowiedz to: artykuł to prawda.\n"
     ]
    }
   ],
   "source": [
    "print(f'Prawidłowa odpowiedz to: artykuł to {\"prawda\" if data.label[random_probe] == 0 else \"fałsz\"}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedz modelu zgadza sie z wartością oczekiwana.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "  f'Odpowiedz modelu {\"nie \" if torch.argmax(ans_model) != data.label[random_probe] else \"\"}zgadza \\\n",
    "sie z wartością oczekiwana.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "marekBaranowski",
   "language": "python",
   "name": "marekbaranowski"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
